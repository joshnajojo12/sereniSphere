import { useEffect, useRef, useState } from "react";
import * as faceapi from "face-api.js";

export default function DemoApp() {
  const videoRef = useRef(null);
  const [emotion, setEmotion] = useState("ğŸ˜ Neutral (simulated Sad)");
  const [confidence, setConfidence] = useState("âš  Moderate (Simulated 60%)");
  const [activated, setActivated] = useState(false);

  // Emojis
  const emotionEmoji = {
    happy: "ğŸ˜Š",
    sad: "ğŸ˜¢",
    angry: "ğŸ˜ ",
    surprised: "ğŸ˜²",
    fearful: "ğŸ˜¨",
    disgusted: "ğŸ¤¢",
    neutral: "ğŸ˜",
  };

  // Load models + start camera
  useEffect(() => {
    const loadModels = async () => {
      try {
        await faceapi.nets.tinyFaceDetector.loadFromUri("/models");
        await faceapi.nets.faceLandmark68Net.loadFromUri("/models");
        await faceapi.nets.faceExpressionNet.loadFromUri("/models");
        startVideo();
      } catch (err) {
        console.error("âŒ Model loading failed:", err);
      }
    };
    loadModels();

    // Simulate confidence score updates
    const interval = setInterval(() => {
      const fakeScores = ["âœ… Confident (90%)", "âš  Moderate (60%)", "âŒ Low Confidence (40%)"];
      const random = fakeScores[Math.floor(Math.random() * fakeScores.length)];
      setConfidence(random);

      // Trigger comfort kit if low
      if (random.includes("Low") && !activated) setActivated(true);
    }, 5000);

    return () => clearInterval(interval);
  }, []);

  const startVideo = () => {
    navigator.mediaDevices
      .getUserMedia({ video: true })
      .then((stream) => {
        if (videoRef.current) {
          videoRef.current.srcObject = stream;
        }
      })
      .catch((err) => console.error("âŒ Camera error:", err));
  };

  // Fake detection: Always trigger SAD for demo
  const handleVideoPlay = () => {
    setTimeout(() => {
      setEmotion(${emotionEmoji.sad} sad);
      setActivated(true);
    }, 2000);
  };

  return (
    <div className="flex flex-col items-center p-6 min-h-screen bg-gradient-to-br from-sky-200 via-pink-100 to-purple-200">
      <h1 className="text-3xl font-bold mb-4">ğŸ§ª Emotion + Voice Detection Demo</h1>

      {/* Webcam */}
      <video
        ref={videoRef}
        autoPlay
        muted
        width="480"
        height="360"
        onPlay={handleVideoPlay}
        className="rounded-lg shadow-lg border mb-4"
      />

      <p className="text-xl">
        Facial Emotion: <span className="font-bold text-pink-600">{emotion}</span>
      </p>
      <p className="text-xl">
        Voice Confidence: <span className="font-bold text-blue-600">{confidence}</span>
      </p>

      {activated && (
        <div className="mt-6 p-6 bg-gradient-to-r from-pink-100 to-purple-100 rounded-xl shadow-lg text-center w-full max-w-md">
          <h3 className="text-xl font-bold text-purple-700 mb-3">
            ğŸŒŸ Comfort Activity Unlocked ğŸŒŸ
          </h3>
          <p className="text-lg text-gray-700 mb-4">Repeat after me:</p>
          <ul className="space-y-2 text-md font-semibold text-gray-800">
            <li>ğŸ’– â€œI am calm and in control.â€</li>
            <li>ğŸŒ¿ â€œThis moment will pass, and Iâ€™ll be stronger.â€</li>
            <li>âœ¨ â€œI am worthy of peace and happiness.â€</li>
          </ul>
        </div>
      )}
    </div>
  );
}